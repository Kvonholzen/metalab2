<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />


<meta name="author" content="Molly Lewis and Christina Bergmann" />


<title>Reproducibility and Publishing Bias</title>

<script src="reproducibility_inner_files/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="reproducibility_inner_files/bootstrap-3.3.5/css/united.min.css" rel="stylesheet" />
<script src="reproducibility_inner_files/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="reproducibility_inner_files/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="reproducibility_inner_files/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="reproducibility_inner_files/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="reproducibility_inner_files/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="reproducibility_inner_files/tocify-1.9.1/jquery.tocify.js"></script>
<script src="reproducibility_inner_files/navigation-1.1/tabsets.js"></script>
<script src="reproducibility_inner_files/navigation-1.1/codefolding.js"></script>


<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; background-color: #f8f8f8; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
pre, code { background-color: #f8f8f8; }
code > span.kw { color: #204a87; font-weight: bold; } /* Keyword */
code > span.dt { color: #204a87; } /* DataType */
code > span.dv { color: #0000cf; } /* DecVal */
code > span.bn { color: #0000cf; } /* BaseN */
code > span.fl { color: #0000cf; } /* Float */
code > span.ch { color: #4e9a06; } /* Char */
code > span.st { color: #4e9a06; } /* String */
code > span.co { color: #8f5902; font-style: italic; } /* Comment */
code > span.ot { color: #8f5902; } /* Other */
code > span.al { color: #ef2929; } /* Alert */
code > span.fu { color: #000000; } /* Function */
code > span.er { color: #a40000; font-weight: bold; } /* Error */
code > span.wa { color: #8f5902; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #000000; } /* Constant */
code > span.sc { color: #000000; } /* SpecialChar */
code > span.vs { color: #4e9a06; } /* VerbatimString */
code > span.ss { color: #4e9a06; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #000000; } /* Variable */
code > span.cf { color: #204a87; font-weight: bold; } /* ControlFlow */
code > span.op { color: #ce5c00; font-weight: bold; } /* Operator */
code > span.pp { color: #8f5902; font-style: italic; } /* Preprocessor */
code > span.ex { } /* Extension */
code > span.at { color: #c4a000; } /* Attribute */
code > span.do { color: #8f5902; font-weight: bold; font-style: italic; } /* Documentation */
code > span.an { color: #8f5902; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #8f5902; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #8f5902; font-weight: bold; font-style: italic; } /* Information */
div.sourceCode {
  overflow-x: visible;
}
</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>


<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>


</head>

<body>

<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
  height: auto;
}
.tabbed-pane {
  padding-top: 12px;
}
button.code-folding-btn:focus {
  outline: none;
}
</style>



<div class="container-fluid main-container">

<!-- tabsets -->
<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});
</script>

<!-- code folding -->
<style type="text/css">
.code-folding-btn { margin-bottom: 4px; }
</style>
<script>
$(document).ready(function () {
  window.initializeCodeFolding("hide" === "show");
});
</script>




<script>
$(document).ready(function ()  {

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_').toLowerCase();
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}


.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
  padding-left: 25px;
  text-indent: 0;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>

<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row-fluid">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="fluid-row" id="header">

<div class="btn-group pull-right">
<button type="button" class="btn btn-default btn-xs dropdown-toggle" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false"><span>Code</span> <span class="caret"></span></button>
<ul class="dropdown-menu" style="min-width: 50px;">
<li><a id="rmd-show-all-code" href="#">Show All Code</a></li>
<li><a id="rmd-hide-all-code" href="#">Hide All Code</a></li>
</ul>
</div>



<h1 class="title toc-ignore">Reproducibility and Publishing Bias</h1>
<h4 class="author"><em>Molly Lewis and Christina Bergmann</em></h4>
<h4 class="date"><em>This report was rendered on 2017-10-24 and will be automatically re-rendered nightly, reflecting any changes in the data or code.</em></h4>

</div>


<div id="introduction" class="section level1">
<h1>Introduction</h1>
<p>To summarize, we find:</p>
<ul>
<li><p>Sample size and effect size are not negatively correlated (in fact they’re <em>positively</em> correlated), suggesting that researchers are not prospectively planning sample sizes.</p></li>
<li><p>Consonant with previous findings, we find that effect sizes decrease over time.</p></li>
<li><p>We also find that sample sizes increase over time, which may account for the decrease in effect sizes over time.</p></li>
<li><p>We find no effect of impact factor of the journal on effect size.</p></li>
</ul>
</div>
<div id="data-availabilityreporting-standards" class="section level1">
<h1>Data availability/reporting standards</h1>
<p>An important component of reproducibility is complete description of data in published report. This is critical both for evaluating an individual study, but also for the purposes of a cumulative science (e.g. meta-analysis). Here we explore the extent to which papers report desired statistics such as test-statistics mean and standard deviation, effect sizes and test statistics.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">counts =<span class="st"> </span>all_data <span class="op">%&gt;%</span>
<span class="st">            </span><span class="kw">summarise</span>(<span class="dt">test_statistic =</span> <span class="kw">sum</span>(<span class="op">!</span><span class="kw">is.na</span>(t) <span class="op">|</span><span class="st"> </span><span class="op">!</span><span class="kw">is.na</span>(F) <span class="op">|</span><span class="st"> </span><span class="op">!</span><span class="kw">is.na</span>(r)),
                      <span class="dt">means =</span> <span class="kw">sum</span>(<span class="op">!</span><span class="kw">is.na</span>(x_<span class="dv">1</span>)),
                      <span class="dt">SD =</span> <span class="kw">sum</span>(<span class="op">!</span><span class="kw">is.na</span>(SD_<span class="dv">1</span>)),
                      <span class="dt">d =</span> <span class="kw">sum</span>(<span class="op">!</span><span class="kw">is.na</span>(d_calc)),
                      <span class="dt">g =</span> <span class="kw">sum</span>(<span class="op">!</span><span class="kw">is.na</span>(g_calc)),
                      <span class="dt">r =</span> <span class="kw">sum</span>(<span class="op">!</span><span class="kw">is.na</span>(r_calc)),
                      <span class="dt">age_range =</span> <span class="kw">sum</span>(<span class="op">!</span><span class="kw">is.na</span>(age_range_<span class="dv">1</span>)),
                      <span class="dt">gender =</span> <span class="kw">sum</span>(<span class="op">!</span><span class="kw">is.na</span>(gender_<span class="dv">1</span>))) <span class="op">%&gt;%</span>
<span class="st">            </span><span class="kw">gather</span>(<span class="st">&quot;coded_variable&quot;</span>, <span class="st">&quot;n&quot;</span>) <span class="op">%&gt;%</span>
<span class="st">            </span><span class="kw">mutate</span>(<span class="dt">coded =</span> <span class="st">&quot;coded&quot;</span>) <span class="op">%&gt;%</span>
<span class="st">            </span><span class="kw">mutate</span>(<span class="dt">total =</span> <span class="kw">nrow</span>(all_data))  <span class="op">%&gt;%</span>
<span class="st">            </span><span class="kw">mutate</span>(<span class="dt">coded_variable =</span> <span class="kw">factor</span>(coded_variable, <span class="dt">levels =</span> <span class="kw">c</span>(<span class="st">&quot;d&quot;</span>, <span class="st">&quot;g&quot;</span>, <span class="st">&quot;r&quot;</span>, <span class="st">&quot;means&quot;</span>,
                                                                        <span class="st">&quot;SD&quot;</span>, <span class="st">&quot;test_statistic&quot;</span>,
                                                                        <span class="st">&quot;age_range&quot;</span>, <span class="st">&quot;gender&quot;</span>)))
counts =<span class="st"> </span>counts <span class="op">%&gt;%</span>
<span class="st">             </span><span class="kw">mutate</span>(<span class="dt">n =</span> total <span class="op">-</span><span class="st"> </span>n, 
                    <span class="dt">coded =</span> <span class="st">&quot;uncoded&quot;</span>)  <span class="op">%&gt;%</span>
<span class="st">             </span><span class="kw">bind_rows</span>(counts) <span class="op">%&gt;%</span>
<span class="st">             </span><span class="kw">mutate</span>(<span class="dt">n_lab =</span> <span class="kw">ifelse</span>(coded <span class="op">==</span><span class="st"> &quot;coded&quot;</span>, n, <span class="st">&quot;&quot;</span>)) <span class="op">%&gt;%</span>
<span class="st">             </span><span class="kw">arrange</span>(coded)
<span class="kw">ggplot</span>(counts) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">geom_bar</span>(<span class="kw">aes</span>(<span class="dt">x =</span> coded_variable, 
               <span class="dt">y =</span> n<span class="op">/</span>total,
               <span class="dt">fill =</span> coded,
              <span class="dt">order =</span> coded), 
           <span class="dt">stat =</span> <span class="st">&quot;identity&quot;</span>) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">ylim</span>(<span class="dv">0</span>,<span class="dv">1</span>) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">ylab</span>(<span class="st">&quot;Proportion coded&quot;</span>) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">xlab</span>(<span class="st">&quot;Coded variable&quot;</span>) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">ggtitle</span>(<span class="st">&quot;All data&quot;</span>) <span class="op">+</span><span class="st"> </span>
<span class="st">   </span><span class="co">#annotate(&quot;text&quot;, x = 1, y = .9, </span>
<span class="st">    </span><span class="co">#        label = paste(&quot;N =&quot;, counts$total[1]), size = 6) + </span>
<span class="st">  </span><span class="kw">scale_fill_manual</span>(<span class="dt">values=</span><span class="kw">c</span>( <span class="st">&quot;lightgreen&quot;</span>, <span class="st">&quot;grey&quot;</span>)) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">geom_text</span>(<span class="kw">aes</span>(<span class="dt">label =</span> n_lab, <span class="dt">x =</span> coded_variable, <span class="dt">y =</span> n<span class="op">/</span>total <span class="op">-</span>.<span class="dv">06</span>) )<span class="op">+</span>
<span class="st">  </span><span class="kw">theme_bw</span>() <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">theme</span>(<span class="dt">panel.border =</span> <span class="kw">element_blank</span>(), 
        <span class="dt">panel.grid.major =</span> <span class="kw">element_blank</span>(), 
        <span class="dt">panel.grid.minor =</span> <span class="kw">element_blank</span>(),
       <span class="dt">axis.line =</span> <span class="kw">element_line</span>(<span class="dt">colour =</span> <span class="st">&quot;black&quot;</span>),
       <span class="dt">text =</span> <span class="kw">element_text</span>(<span class="dt">size=</span><span class="dv">20</span>),
       <span class="dt">axis.text.x =</span> <span class="kw">element_text</span>(<span class="dt">angle =</span> <span class="dv">30</span>, <span class="dt">hjust =</span> <span class="dv">1</span>))</code></pre></div>
<p><img src="reproducibility_inner_files/figure-html/unnamed-chunk-2-1.png" width="1056" /> This analysis is in practice difficult because our many of our source MA’s include effect sizes that were included by the coders. Similarly, the proportion of coded gender in many cases reflects only that the coder chose not to code that, not that this information was not present. Nevertheless, this analysis gives us a good sense of the the proportion of papers that report means and standard deviations (about two-thirds).</p>
<p>By MA</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">counts =<span class="st"> </span>all_data <span class="op">%&gt;%</span>
<span class="st">            </span><span class="kw">group_by</span>(dataset) <span class="op">%&gt;%</span>
<span class="st">            </span><span class="kw">summarise</span>(<span class="dt">test_statistic =</span> <span class="kw">sum</span>(<span class="op">!</span><span class="kw">is.na</span>(t) <span class="op">|</span><span class="st"> </span><span class="op">!</span><span class="kw">is.na</span>(F)),
                      <span class="dt">means =</span> <span class="kw">sum</span>(<span class="op">!</span><span class="kw">is.na</span>(x_<span class="dv">1</span>)),
                      <span class="dt">SD =</span> <span class="kw">sum</span>(<span class="op">!</span><span class="kw">is.na</span>(SD_<span class="dv">1</span>)),
                      <span class="dt">d =</span> <span class="kw">sum</span>(<span class="op">!</span><span class="kw">is.na</span>(d_calc)),
                      <span class="dt">g =</span> <span class="kw">sum</span>(<span class="op">!</span><span class="kw">is.na</span>(g_calc)),
                      <span class="dt">r =</span> <span class="kw">sum</span>(<span class="op">!</span><span class="kw">is.na</span>(r_calc)),
                      <span class="dt">age_range =</span> <span class="kw">sum</span>(<span class="op">!</span><span class="kw">is.na</span>(age_range_<span class="dv">1</span>)),
                      <span class="dt">gender =</span> <span class="kw">sum</span>(<span class="op">!</span><span class="kw">is.na</span>(gender_<span class="dv">1</span>)),
                      <span class="dt">total =</span> <span class="kw">n</span>()) <span class="op">%&gt;%</span>
<span class="st">            </span><span class="kw">gather</span>(coded_variable, n, <span class="op">-</span>dataset, <span class="op">-</span>total) <span class="op">%&gt;%</span>
<span class="st">            </span><span class="kw">mutate</span>(<span class="dt">coded =</span> <span class="st">&quot;coded&quot;</span>) <span class="op">%&gt;%</span>
<span class="st">            </span><span class="kw">mutate</span>(<span class="dt">coded_variable =</span> <span class="kw">factor</span>(coded_variable, <span class="dt">levels =</span> <span class="kw">c</span>(<span class="st">&quot;d&quot;</span>, <span class="st">&quot;g&quot;</span>, <span class="st">&quot;r&quot;</span>, <span class="st">&quot;means&quot;</span>,
                                                                        <span class="st">&quot;SD&quot;</span>, <span class="st">&quot;test_statistic&quot;</span>,
                                                                        <span class="st">&quot;age_range&quot;</span>, <span class="st">&quot;gender&quot;</span>)))

counts =<span class="st"> </span>counts <span class="op">%&gt;%</span>
<span class="st">             </span><span class="kw">mutate</span>(<span class="dt">n =</span> total <span class="op">-</span><span class="st"> </span>n, 
                    <span class="dt">coded =</span> <span class="st">&quot;uncoded&quot;</span>)  <span class="op">%&gt;%</span>
<span class="st">             </span><span class="kw">bind_rows</span>(counts) <span class="op">%&gt;%</span>
<span class="st">             </span><span class="kw">mutate</span>(<span class="dt">n_lab =</span> <span class="kw">ifelse</span>(coded <span class="op">==</span><span class="st"> &quot;coded&quot;</span>, n, <span class="st">&quot;&quot;</span>)) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">arrange</span>(coded)

<span class="kw">ggplot</span>(counts, <span class="kw">aes</span>(<span class="dt">fill =</span> coded)) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">geom_bar</span>(<span class="kw">aes</span>(<span class="dt">x =</span> <span class="kw">factor</span>(coded_variable), 
               <span class="dt">y =</span> n<span class="op">/</span>total),  ## FIX THIS
           <span class="dt">stat =</span> <span class="st">&quot;identity&quot;</span>,
           <span class="dt">position =</span> <span class="st">&quot;fill&quot;</span>) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">facet_wrap</span>(<span class="op">~</span>dataset, <span class="dt">ncol=</span><span class="dv">2</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">ylim</span>(<span class="dv">0</span>,<span class="dv">1</span>) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">ylab</span>(<span class="st">&quot;Proportion coded&quot;</span>) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">xlab</span>(<span class="st">&quot;Coded variable&quot;</span>) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">scale_fill_manual</span>(<span class="dt">values =</span> <span class="kw">c</span>(<span class="st">&quot;lightgreen&quot;</span>, <span class="st">&quot;grey&quot;</span>)) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">geom_text</span>(<span class="kw">aes</span>(<span class="dt">label =</span> n_lab,
              <span class="dt">x =</span> coded_variable, 
              <span class="dt">y =</span> n<span class="op">/</span>total <span class="op">-</span>.<span class="dv">06</span>)) <span class="op">+</span>
<span class="st">  </span><span class="kw">theme_bw</span>() <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">theme</span>(<span class="dt">panel.border =</span> <span class="kw">element_blank</span>(), 
        <span class="dt">panel.grid.major =</span> <span class="kw">element_blank</span>(), 
        <span class="dt">panel.grid.minor =</span> <span class="kw">element_blank</span>(),
        <span class="dt">axis.line =</span> <span class="kw">element_line</span>(<span class="dt">colour =</span> <span class="st">&quot;black&quot;</span>),
        <span class="dt">text =</span> <span class="kw">element_text</span>(<span class="dt">size=</span><span class="dv">20</span>),
        <span class="dt">strip.background  =</span> <span class="kw">element_blank</span>(), 
        <span class="dt">axis.text.x =</span> <span class="kw">element_text</span>(<span class="dt">angle =</span> <span class="dv">30</span>, <span class="dt">hjust =</span> <span class="dv">1</span>))</code></pre></div>
<p><img src="reproducibility_inner_files/figure-html/unnamed-chunk-3-1.png" width="960" /></p>
</div>
<div id="sample-size-planning" class="section level1">
<h1>Sample size planning</h1>
<p>If sample size and effect sizes are appropriately coupled, we should expect sample size to decrease as effect size increases. We test this by looking at the relationship between sample sizes and effect size, after residualizing out the effect of (1) phenomenon, (2) age, (3) method, and (4) response mode.</p>
<p>Compute residuals.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">full.model =<span class="st"> </span><span class="kw">rma</span>(d_calc <span class="op">~</span><span class="st"> </span>method <span class="op">+</span><span class="st"> </span>response_mode <span class="op">+</span><span class="st"> </span>mean_age_<span class="dv">1</span> <span class="op">+</span><span class="st"> </span>dataset, 
        <span class="dt">vi =</span> d_var_calc, <span class="dt">data =</span> all_data, <span class="dt">method =</span> <span class="st">&quot;REML&quot;</span>)

p.model =<span class="st"> </span><span class="kw">rma</span>(d_calc <span class="op">~</span><span class="st">  </span>method <span class="op">+</span><span class="st"> </span>mean_age_<span class="dv">1</span> <span class="op">+</span><span class="st"> </span>dataset, 
        <span class="dt">vi =</span> d_var_calc, <span class="dt">data =</span> all_data, <span class="dt">method =</span> <span class="st">&quot;REML&quot;</span>)

residuals =<span class="st"> </span><span class="kw">rstandard</span>(full.model)

all_data =<span class="st"> </span>all_data <span class="op">%&gt;%</span>
<span class="st">            </span><span class="kw">bind_cols</span>(<span class="kw">as.data.frame</span>(residuals<span class="op">$</span>resid, <span class="dt">stringsAsFactors =</span> <span class="ot">FALSE</span>),
                      <span class="kw">as.data.frame</span>(residuals<span class="op">$</span>z, <span class="dt">stringsAsFactors =</span> <span class="ot">FALSE</span>)) <span class="op">%&gt;%</span>
<span class="st">            </span><span class="kw">rename</span>(<span class="dt">residual.d =</span> <span class="st">`</span><span class="dt">residuals$resid</span><span class="st">`</span>, 
                   <span class="dt">residual.d.s =</span> <span class="st">`</span><span class="dt">residuals$z</span><span class="st">`</span>) <span class="co"># standardized</span></code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">all_data =<span class="st"> </span>all_data <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">n_total =</span> <span class="kw">ifelse</span>(<span class="op">!</span><span class="kw">is.na</span>(n_<span class="dv">2</span>), n_<span class="dv">1</span> <span class="op">+</span><span class="st"> </span>n_<span class="dv">2</span>, n_<span class="dv">1</span>))  

<span class="kw">ggplot</span>(all_data , <span class="kw">aes</span>(<span class="dt">y =</span> n_total, <span class="dt">x =</span> residual.d.s, <span class="dt">color =</span> dataset)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_point</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_smooth</span>(<span class="dt">method =</span> <span class="st">&quot;lm&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">theme_bw</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">xlab</span>(<span class="st">&quot;Standardized residual effect size&quot;</span>) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">ylab</span>(<span class="st">&quot;Sample size&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">facet_wrap</span>(<span class="op">~</span>dataset, <span class="dt">scales =</span> <span class="st">&quot;free&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">theme</span>(<span class="dt">legend.position=</span><span class="st">&quot;none&quot;</span>)</code></pre></div>
<p><img src="reproducibility_inner_files/figure-html/unnamed-chunk-5-1.png" width="672" /></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">all_data <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">group_by</span>(dataset) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">do</span>(<span class="kw">tidy</span>(<span class="kw">cor.test</span>(.<span class="op">$</span>residual.d.s,.<span class="op">$</span>n_total))) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">select</span>(dataset, estimate, p.value) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">sig =</span> <span class="kw">ifelse</span>(p.value <span class="op">&lt;</span><span class="st"> </span>.<span class="dv">05</span>, <span class="st">&quot;*&quot;</span>, <span class="st">&quot;&quot;</span>)) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">kable</span>()</code></pre></div>
<table>
<thead>
<tr class="header">
<th align="left">dataset</th>
<th align="right">estimate</th>
<th align="right">p.value</th>
<th align="left">sig</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Categorization Bias</td>
<td align="right">0.1786323</td>
<td align="right">0.1128823</td>
<td align="left"></td>
</tr>
<tr class="even">
<td align="left">Gaze following</td>
<td align="right">0.0243553</td>
<td align="right">0.8929789</td>
<td align="left"></td>
</tr>
<tr class="odd">
<td align="left">Infant directed speech preference</td>
<td align="right">0.0713839</td>
<td align="right">0.5427918</td>
<td align="left"></td>
</tr>
<tr class="even">
<td align="left">Label advantage in concept learning</td>
<td align="right">0.1628867</td>
<td align="right">0.1053995</td>
<td align="left"></td>
</tr>
<tr class="odd">
<td align="left">Mutual exclusivity</td>
<td align="right">-0.0802104</td>
<td align="right">0.4628634</td>
<td align="left"></td>
</tr>
<tr class="even">
<td align="left">Online word recognition</td>
<td align="right">-0.2796763</td>
<td align="right">0.3127135</td>
<td align="left"></td>
</tr>
<tr class="odd">
<td align="left">Phonotactic learning</td>
<td align="right">0.0043939</td>
<td align="right">0.9766160</td>
<td align="left"></td>
</tr>
<tr class="even">
<td align="left">Pointing and vocabulary (concurrent)</td>
<td align="right">0.2359597</td>
<td align="right">0.4603219</td>
<td align="left"></td>
</tr>
<tr class="odd">
<td align="left">Pointing and vocabulary (longitudinal)</td>
<td align="right">-0.0209616</td>
<td align="right">0.9342043</td>
<td align="left"></td>
</tr>
<tr class="even">
<td align="left">Sound symbolism</td>
<td align="right">-0.0674878</td>
<td align="right">0.6633646</td>
<td align="left"></td>
</tr>
<tr class="odd">
<td align="left">Statistical sound category learning</td>
<td align="right">0.0560271</td>
<td align="right">0.8252400</td>
<td align="left"></td>
</tr>
<tr class="even">
<td align="left">Vowel discrimination (native)</td>
<td align="right">-0.1666192</td>
<td align="right">0.0444275</td>
<td align="left">*</td>
</tr>
<tr class="odd">
<td align="left">Vowel discrimination (non-native)</td>
<td align="right">0.1900382</td>
<td align="right">0.1909133</td>
<td align="left"></td>
</tr>
<tr class="even">
<td align="left">Word segmentation</td>
<td align="right">-0.0069386</td>
<td align="right">0.9048961</td>
<td align="left"></td>
</tr>
</tbody>
</table>
<p>Essentially no evidence that researchers are prospectively planning sample size.</p>
<p>Collapsing across MAs:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(all_data , <span class="kw">aes</span>(<span class="dt">y =</span> n_total, <span class="dt">x =</span> residual.d.s)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_point</span>(<span class="kw">aes</span>( <span class="dt">color =</span> dataset)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_smooth</span>(<span class="dt">method =</span> <span class="st">&quot;lm&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">theme_bw</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">xlab</span>(<span class="st">&quot;Standardized residual effect size&quot;</span>) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">ylab</span>(<span class="st">&quot;Sample size&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">theme</span>(<span class="dt">legend.position=</span><span class="st">&quot;none&quot;</span>)</code></pre></div>
<p><img src="reproducibility_inner_files/figure-html/unnamed-chunk-7-1.png" width="672" /></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">kable</span>(<span class="kw">tidy</span>(<span class="kw">cor.test</span>(all_data<span class="op">$</span>residual.d.s,all_data<span class="op">$</span>n_total)))</code></pre></div>
<table>
<thead>
<tr class="header">
<th align="right">estimate</th>
<th align="right">statistic</th>
<th align="right">p.value</th>
<th align="right">parameter</th>
<th align="right">conf.low</th>
<th align="right">conf.high</th>
<th align="left">method</th>
<th align="left">alternative</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">-0.010661</td>
<td align="right">-0.3405039</td>
<td align="right">0.7335472</td>
<td align="right">1020</td>
<td align="right">-0.0719359</td>
<td align="right">0.0506941</td>
<td align="left">Pearson’s product-moment correlation</td>
<td align="left">two.sided</td>
</tr>
</tbody>
</table>
<p>Here we see a <em>positive</em> relationship between effect size and sample size: As effect sizes get bigger, sample sizes get bigger. If researchers were prospectively planning studies, we would expect that opposite pattern.</p>
</div>
<div id="year-bias" class="section level1">
<h1>Year bias</h1>
<p>If studies are randomly sampled from the population of possible studies, effect sizes should not be biased by year. Alternatively, there is previous work suggesting that effect sizes decrease over time in a literature (Jennions &amp; Møller, 2002; Leimu &amp; Koricheva 2004, Lehrer 2010). Here we examine this possibiilty, using residualized effect sizes.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">all_data =<span class="st"> </span>all_data <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">year =</span> <span class="kw">as.numeric</span>(<span class="kw">unlist</span>(<span class="kw">lapply</span>(<span class="kw">strsplit</span>(<span class="kw">unlist</span>(study_ID),
                                                  <span class="st">&quot;[^0-9]+&quot;</span>),  <span class="cf">function</span>(x) <span class="kw">unlist</span>(x)[<span class="dv">2</span>])))) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">year =</span> <span class="kw">ifelse</span>(<span class="kw">grepl</span>(<span class="st">&quot;submitted&quot;</span>,study_ID), <span class="dv">2016</span>, year)) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">year =</span> <span class="kw">ifelse</span>(dataset <span class="op">==</span><span class="st"> &quot;Phonotactic learning&quot;</span> <span class="op">|</span><span class="st"> </span>dataset <span class="op">==</span><span class="st"> &quot;Statistical sound category learning&quot;</span>, <span class="kw">as.numeric</span>(<span class="kw">unlist</span>(<span class="kw">lapply</span>(<span class="kw">strsplit</span>(<span class="kw">unlist</span>(short_cite),
                                                  <span class="st">&quot;[^0-9]+&quot;</span>),  <span class="cf">function</span>(x) <span class="kw">unlist</span>(x)[<span class="dv">2</span>]))), year))

<span class="kw">ggplot</span>(all_data , <span class="kw">aes</span>(<span class="dt">x =</span> year, <span class="dt">y =</span> residual.d.s, <span class="dt">color =</span> dataset)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_point</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_smooth</span>(<span class="dt">method =</span> <span class="st">&quot;lm&quot;</span>, <span class="dt">colour =</span> <span class="st">&quot;black&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">facet_wrap</span>(<span class="op">~</span><span class="st"> </span>dataset, <span class="dt">scales =</span> <span class="st">&quot;free_y&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">theme_bw</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">xlab</span>(<span class="st">&quot;published year&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">ylab</span>(<span class="st">&quot;standardized residual effect size&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">theme</span>(<span class="dt">legend.position=</span><span class="st">&quot;none&quot;</span>)</code></pre></div>
<p><img src="reproducibility_inner_files/figure-html/unnamed-chunk-8-1.png" width="672" /></p>
<p>We see some bias of year here: In four cases (gaze following, IDS, statistical sound category, and word segementation), we see effect size decrease with year. For ME, we see a positive effect (but that’s probably due to Frank et al 2015).</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">all_data <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">group_by</span>(dataset) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">do</span>(<span class="kw">tidy</span>(<span class="kw">cor.test</span>(.<span class="op">$</span>residual.d.s,.<span class="op">$</span>year))) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">select</span>(dataset, estimate, p.value) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">sig =</span> <span class="kw">ifelse</span>(p.value <span class="op">&lt;</span><span class="st"> </span>.<span class="dv">05</span>, <span class="st">&quot;*&quot;</span>, <span class="st">&quot;&quot;</span>)) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">kable</span>()</code></pre></div>
<table>
<thead>
<tr class="header">
<th align="left">dataset</th>
<th align="right">estimate</th>
<th align="right">p.value</th>
<th align="left">sig</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Categorization Bias</td>
<td align="right">-0.1275493</td>
<td align="right">0.2595340</td>
<td align="left"></td>
</tr>
<tr class="even">
<td align="left">Gaze following</td>
<td align="right">-0.3615803</td>
<td align="right">0.0386804</td>
<td align="left">*</td>
</tr>
<tr class="odd">
<td align="left">Infant directed speech preference</td>
<td align="right">-0.2323693</td>
<td align="right">0.0448426</td>
<td align="left">*</td>
</tr>
<tr class="even">
<td align="left">Label advantage in concept learning</td>
<td align="right">-0.0969621</td>
<td align="right">0.3372090</td>
<td align="left"></td>
</tr>
<tr class="odd">
<td align="left">Mutual exclusivity</td>
<td align="right">0.2537340</td>
<td align="right">0.0184075</td>
<td align="left">*</td>
</tr>
<tr class="even">
<td align="left">Online word recognition</td>
<td align="right">0.5455340</td>
<td align="right">0.0354270</td>
<td align="left">*</td>
</tr>
<tr class="odd">
<td align="left">Phonotactic learning</td>
<td align="right">-0.0706944</td>
<td align="right">0.6367861</td>
<td align="left"></td>
</tr>
<tr class="even">
<td align="left">Pointing and vocabulary (concurrent)</td>
<td align="right">0.7536759</td>
<td align="right">0.0046414</td>
<td align="left">*</td>
</tr>
<tr class="odd">
<td align="left">Pointing and vocabulary (longitudinal)</td>
<td align="right">-0.0584892</td>
<td align="right">0.8176798</td>
<td align="left"></td>
</tr>
<tr class="even">
<td align="left">Sound symbolism</td>
<td align="right">0.2292760</td>
<td align="right">0.1343709</td>
<td align="left"></td>
</tr>
<tr class="odd">
<td align="left">Statistical sound category learning</td>
<td align="right">-0.4726345</td>
<td align="right">0.0476236</td>
<td align="left">*</td>
</tr>
<tr class="even">
<td align="left">Vowel discrimination (native)</td>
<td align="right">-0.0801601</td>
<td align="right">0.3361495</td>
<td align="left"></td>
</tr>
<tr class="odd">
<td align="left">Vowel discrimination (non-native)</td>
<td align="right">0.0245527</td>
<td align="right">0.8670104</td>
<td align="left"></td>
</tr>
<tr class="even">
<td align="left">Word segmentation</td>
<td align="right">-0.0693456</td>
<td align="right">0.2318862</td>
<td align="left"></td>
</tr>
</tbody>
</table>
<p>Here’s the same analysis, but fitting meta-analytic models instead (which allows us to weight by study precision).</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">overall_es &lt;-<span class="st"> </span><span class="cf">function</span>(ma_data){
  <span class="co"># get datasets where we only have one levels for method</span>
  bad_datasets =<span class="st"> </span>all_data <span class="op">%&gt;%</span>
<span class="st">    </span><span class="kw">group_by</span>(dataset, method) <span class="op">%&gt;%</span>
<span class="st">    </span><span class="kw">slice</span>(<span class="dv">1</span>) <span class="op">%&gt;%</span>
<span class="st">    </span><span class="kw">select</span>(dataset, method) <span class="op">%&gt;%</span>
<span class="st">    </span><span class="kw">group_by</span>(dataset) <span class="op">%&gt;%</span>
<span class="st">    </span><span class="kw">summarize</span>(<span class="dt">n =</span> <span class="kw">n</span>()) <span class="op">%&gt;%</span>
<span class="st">    </span><span class="kw">filter</span>(n <span class="op">==</span><span class="st"> </span><span class="dv">1</span>) <span class="op">%&gt;%</span>
<span class="st">    </span><span class="kw">select</span>(dataset)

<span class="cf">if</span>(<span class="kw">is.element</span>(ma_data<span class="op">$</span>dataset[<span class="dv">1</span>], bad_datasets<span class="op">$</span>dataset)){  
        model =<span class="st"> </span>metafor<span class="op">::</span><span class="kw">rma</span>(ma_data<span class="op">$</span>d_calc<span class="op">~</span><span class="st"> </span>ma_data<span class="op">$</span>mean_age_<span class="dv">1</span> <span class="op">+</span><span class="st"> </span>ma_data<span class="op">$</span>year, ma_data<span class="op">$</span>d_var_calc, <span class="dt">method =</span> <span class="st">&quot;REML&quot;</span>,
               <span class="dt">control =</span> <span class="kw">list</span>(<span class="dt">maxiter =</span> <span class="dv">1000</span>, <span class="dt">stepadj =</span> <span class="fl">0.5</span>))
} <span class="cf">else</span> {
        model =<span class="st"> </span>metafor<span class="op">::</span><span class="kw">rma</span>(ma_data<span class="op">$</span>d_calc<span class="op">~</span><span class="st"> </span>ma_data<span class="op">$</span>mean_age_<span class="dv">1</span> <span class="op">+</span><span class="st"> </span>ma_data<span class="op">$</span>year <span class="op">+</span><span class="st"> </span>ma_data<span class="op">$</span>method , ma_data<span class="op">$</span>d_var_calc, <span class="dt">method =</span> <span class="st">&quot;REML&quot;</span>,
             <span class="dt">control =</span> <span class="kw">list</span>(<span class="dt">maxiter =</span> <span class="dv">1000</span>, <span class="dt">stepadj =</span> <span class="fl">0.5</span>))
}
  <span class="kw">data.frame</span>(<span class="dt">dataset =</span> ma_data<span class="op">$</span>dataset[<span class="dv">1</span>],
             <span class="dt">year.effect =</span> model<span class="op">$</span>b[<span class="dv">3</span>],
             <span class="dt">year.pvalue =</span> model<span class="op">$</span>pval[<span class="dv">3</span>],
             <span class="dt">stringsAsFactors =</span> <span class="ot">FALSE</span>)
}

all_data <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">split</span>(.<span class="op">$</span>dataset) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">map</span>(<span class="cf">function</span>(ma_data) <span class="kw">overall_es</span>(ma_data)) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">bind_rows</span>() <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">sig =</span> <span class="kw">ifelse</span>(year.pvalue <span class="op">&lt;</span><span class="st"> </span>.<span class="dv">05</span>, <span class="st">&quot;*&quot;</span>, <span class="st">&quot;&quot;</span>)) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">kable</span>()</code></pre></div>
<table>
<thead>
<tr class="header">
<th align="left">dataset</th>
<th align="right">year.effect</th>
<th align="right">year.pvalue</th>
<th align="left">sig</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Categorization Bias</td>
<td align="right">-0.0608129</td>
<td align="right">0.2951118</td>
<td align="left"></td>
</tr>
<tr class="even">
<td align="left">Gaze following</td>
<td align="right">-0.0353034</td>
<td align="right">0.1093870</td>
<td align="left"></td>
</tr>
<tr class="odd">
<td align="left">Infant directed speech preference</td>
<td align="right">-0.0358175</td>
<td align="right">0.0047120</td>
<td align="left">*</td>
</tr>
<tr class="even">
<td align="left">Label advantage in concept learning</td>
<td align="right">-0.0078726</td>
<td align="right">0.5199541</td>
<td align="left"></td>
</tr>
<tr class="odd">
<td align="left">Mutual exclusivity</td>
<td align="right">0.0174397</td>
<td align="right">0.2690138</td>
<td align="left"></td>
</tr>
<tr class="even">
<td align="left">Online word recognition</td>
<td align="right">0.1518804</td>
<td align="right">0.0044119</td>
<td align="left">*</td>
</tr>
<tr class="odd">
<td align="left">Phonotactic learning</td>
<td align="right">-0.0069573</td>
<td align="right">0.7404821</td>
<td align="left"></td>
</tr>
<tr class="even">
<td align="left">Pointing and vocabulary (concurrent)</td>
<td align="right">0.0239604</td>
<td align="right">0.2055760</td>
<td align="left"></td>
</tr>
<tr class="odd">
<td align="left">Pointing and vocabulary (longitudinal)</td>
<td align="right">-0.0144813</td>
<td align="right">0.4535335</td>
<td align="left"></td>
</tr>
<tr class="even">
<td align="left">Sound symbolism</td>
<td align="right">0.0487791</td>
<td align="right">0.3155883</td>
<td align="left"></td>
</tr>
<tr class="odd">
<td align="left">Statistical sound category learning</td>
<td align="right">-0.0689837</td>
<td align="right">0.0248699</td>
<td align="left">*</td>
</tr>
<tr class="even">
<td align="left">Vowel discrimination (native)</td>
<td align="right">-0.0182265</td>
<td align="right">0.0497690</td>
<td align="left">*</td>
</tr>
<tr class="odd">
<td align="left">Vowel discrimination (non-native)</td>
<td align="right">0.0176743</td>
<td align="right">0.0839001</td>
<td align="left"></td>
</tr>
<tr class="even">
<td align="left">Word segmentation</td>
<td align="right">-0.0079667</td>
<td align="right">0.0711348</td>
<td align="left"></td>
</tr>
<tr class="odd">
<td align="left">Same as before but now here also effect o</td>
<td align="right">f year for nat</td>
<td align="right">ive vowels.</td>
<td align="left"></td>
</tr>
</tbody>
</table>
<p>Collapsing across meta-analyses.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(all_data , <span class="kw">aes</span>(<span class="dt">x =</span> year, <span class="dt">y =</span> residual.d.s, <span class="dt">color =</span> dataset)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_point</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_smooth</span>(<span class="dt">method =</span> <span class="st">&quot;lm&quot;</span>, <span class="dt">colour =</span> <span class="st">&quot;black&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">theme_bw</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">xlab</span>(<span class="st">&quot;published year&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">ylab</span>(<span class="st">&quot;standardized residual effect size&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">theme</span>(<span class="dt">legend.position=</span><span class="st">&quot;none&quot;</span>)</code></pre></div>
<p><img src="reproducibility_inner_files/figure-html/unnamed-chunk-11-1.png" width="672" /></p>
<p>Effect size decreases over time. It’s not clear what the right analysis here is.</p>
<p>Correlation with raw effect sizes in significant.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">kable</span>(<span class="kw">tidy</span>(<span class="kw">cor.test</span>(all_data<span class="op">$</span>d_calc,all_data<span class="op">$</span>year)))</code></pre></div>
<table>
<thead>
<tr class="header">
<th align="right">estimate</th>
<th align="right">statistic</th>
<th align="right">p.value</th>
<th align="right">parameter</th>
<th align="right">conf.low</th>
<th align="right">conf.high</th>
<th align="left">method</th>
<th align="left">alternative</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">-0.1779643</td>
<td align="right">-5.775924</td>
<td align="right">0</td>
<td align="right">1020</td>
<td align="right">-0.236703</td>
<td align="right">-0.1179293</td>
<td align="left">Pearson’s product-moment correlation</td>
<td align="left">two.sided</td>
</tr>
</tbody>
</table>
<p>Correlation with residualized effect sizes is not significant.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">kable</span>(<span class="kw">tidy</span>(<span class="kw">cor.test</span>(all_data<span class="op">$</span>residual.d.s,all_data<span class="op">$</span>year)))</code></pre></div>
<table>
<thead>
<tr class="header">
<th align="right">estimate</th>
<th align="right">statistic</th>
<th align="right">p.value</th>
<th align="right">parameter</th>
<th align="right">conf.low</th>
<th align="right">conf.high</th>
<th align="left">method</th>
<th align="left">alternative</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">-0.0433229</td>
<td align="right">-1.384923</td>
<td align="right">0.1663787</td>
<td align="right">1020</td>
<td align="right">-0.1043676</td>
<td align="right">0.0180469</td>
<td align="left">Pearson’s product-moment correlation</td>
<td align="left">two.sided</td>
</tr>
</tbody>
</table>
<p>RMA with year as moderator is significant when method is included as moderator.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">rma</span>(d_calc <span class="op">~</span><span class="st"> </span>method <span class="op">+</span><span class="st"> </span>mean_age_<span class="dv">1</span> <span class="op">+</span><span class="st"> </span>dataset <span class="op">+</span><span class="st"> </span>year, 
        <span class="dt">vi =</span> d_var_calc, <span class="dt">data =</span> all_data, <span class="dt">method =</span> <span class="st">&quot;REML&quot;</span>)</code></pre></div>
<pre><code>## 
## Mixed-Effects Model (k = 1022; tau^2 estimator: REML)
## 
## tau^2 (estimated amount of residual heterogeneity):     0.3174 (SE = 0.0178)
## tau (square root of estimated tau^2 value):             0.5634
## I^2 (residual heterogeneity / unaccounted variability): 86.13%
## H^2 (unaccounted variability / sampling variability):   7.21
## R^2 (amount of heterogeneity accounted for):            30.08%
## 
## Test for Residual Heterogeneity: 
## QE(df = 996) = 5127.8755, p-val &lt; .0001
## 
## Test of Moderators (coefficient(s) 2:26): 
## QM(df = 25) = 319.8136, p-val &lt; .0001
## 
## Model Results:
## 
##                                              estimate      se     zval
## intrcpt                                       10.4421  7.0148   1.4886
## methodcentral fixation                        -0.2216  0.3171  -0.6988
## methodconditioned head-turn                    0.5140  0.3264   1.5747
## methodforced-choice                            0.5596  0.4070   1.3749
## methodhead-turn preference procedure          -0.1822  0.3216  -0.5667
## methodhigh-amplitude sucking                   0.4452  0.3857   1.1541
## methodhybrid visual habituation procedure     -0.9770  0.4322  -2.2602
## methodlooking while listening                 -0.2009  0.3557  -0.5649
## methododdball                                 -0.2578  0.3794  -0.6793
## methodpointing                                 0.6817  0.4530   1.5048
## methodstimulus alternation                    -0.2914  0.3360  -0.8673
## methodword-object pairing                     -0.6813  0.4756  -1.4326
## mean_age_1                                    -0.0001  0.0000  -1.5999
## datasetGaze following                          0.6796  0.1543   4.4044
## datasetInfant directed speech preference       0.7834  0.2759   2.8393
## datasetLabel advantage in concept learning    -0.1060  0.1283  -0.8259
## datasetMutual exclusivity                      0.4282  0.1253   3.4184
## datasetOnline word recognition                 1.5652  0.3183   4.9171
## datasetPhonotactic learning                    0.3115  0.2947   1.0573
## datasetPointing and vocabulary (concurrent)    0.4006  0.3241   1.2359
## datasetSound symbolism                         0.3549  0.2589   1.3711
## datasetStatistical sound category learning     0.0664  0.3146   0.2111
## datasetVowel discrimination (native)           0.7134  0.2802   2.5456
## datasetVowel discrimination (non-native)       0.6483  0.2937   2.2073
## datasetWord segmentation                       0.4714  0.2805   1.6804
## year                                          -0.0052  0.0035  -1.4926
##                                                pval    ci.lb    ci.ub     
## intrcpt                                      0.1366  -3.3066  24.1908     
## methodcentral fixation                       0.4847  -0.8431   0.3999     
## methodconditioned head-turn                  0.1153  -0.1258   1.1538     
## methodforced-choice                          0.1692  -0.2381   1.3573     
## methodhead-turn preference procedure         0.5709  -0.8125   0.4480     
## methodhigh-amplitude sucking                 0.2485  -0.3109   1.2012     
## methodhybrid visual habituation procedure    0.0238  -1.8242  -0.1298    *
## methodlooking while listening                0.5721  -0.8981   0.4962     
## methododdball                                0.4970  -1.0015   0.4859     
## methodpointing                               0.1324  -0.2062   1.5696     
## methodstimulus alternation                   0.3858  -0.9498   0.3671     
## methodword-object pairing                    0.1520  -1.6133   0.2508     
## mean_age_1                                   0.1096  -0.0002   0.0000     
## datasetGaze following                        &lt;.0001   0.3772   0.9820  ***
## datasetInfant directed speech preference     0.0045   0.2426   1.3242   **
## datasetLabel advantage in concept learning   0.4088  -0.3574   0.1455     
## datasetMutual exclusivity                    0.0006   0.1827   0.6737  ***
## datasetOnline word recognition               &lt;.0001   0.9413   2.1891  ***
## datasetPhonotactic learning                  0.2904  -0.2660   0.8891     
## datasetPointing and vocabulary (concurrent)  0.2165  -0.2347   1.0359     
## datasetSound symbolism                       0.1703  -0.1524   0.8623     
## datasetStatistical sound category learning   0.8328  -0.5503   0.6831     
## datasetVowel discrimination (native)         0.0109   0.1641   1.2626    *
## datasetVowel discrimination (non-native)     0.0273   0.0726   1.2239    *
## datasetWord segmentation                     0.0929  -0.0784   1.0211    .
## year                                         0.1356  -0.0121   0.0016     
## 
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>RMA with year as moderator is significant when response mode is included as moderator.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">rma</span>(d_calc <span class="op">~</span><span class="st"> </span>response_mode <span class="op">+</span><span class="st"> </span>mean_age_<span class="dv">1</span> <span class="op">+</span><span class="st"> </span>dataset <span class="op">+</span><span class="st"> </span>year, 
        <span class="dt">vi =</span> d_var_calc, <span class="dt">data =</span> all_data, <span class="dt">method =</span> <span class="st">&quot;REML&quot;</span>)</code></pre></div>
<pre><code>## 
## Mixed-Effects Model (k = 1022; tau^2 estimator: REML)
## 
## tau^2 (estimated amount of residual heterogeneity):     0.3312 (SE = 0.0184)
## tau (square root of estimated tau^2 value):             0.5755
## I^2 (residual heterogeneity / unaccounted variability): 86.64%
## H^2 (unaccounted variability / sampling variability):   7.48
## R^2 (amount of heterogeneity accounted for):            27.04%
## 
## Test for Residual Heterogeneity: 
## QE(df = 1002) = 5263.0049, p-val &lt; .0001
## 
## Test of Moderators (coefficient(s) 2:20): 
## QM(df = 19) = 279.8832, p-val &lt; .0001
## 
## Model Results:
## 
##                                                estimate      se     zval
## intrcpt                                         19.3530  6.3791   3.0338
## response_modeEEG                                -0.3394  0.2068  -1.6415
## response_modeeye-tracking                       -0.3171  0.0577  -5.4918
## response_modeNIRS                               -0.4043  0.1663  -2.4317
## response_modeother                               0.0364  0.2841   0.1281
## mean_age_1                                      -0.0001  0.0000  -1.5447
## datasetGaze following                            1.0422  0.1614   6.4590
## datasetInfant directed speech preference         0.2490  0.1367   1.8220
## datasetLabel advantage in concept learning       0.1226  0.1294   0.9470
## datasetMutual exclusivity                        0.5763  0.1242   4.6411
## datasetOnline word recognition                   1.1847  0.2006   5.9064
## datasetPhonotactic learning                     -0.0459  0.1554  -0.2953
## datasetPointing and vocabulary (concurrent)      0.4856  0.4022   1.2074
## datasetPointing and vocabulary (longitudinal)    0.1163  0.3557   0.3271
## datasetSound symbolism                           0.0556  0.1568   0.3549
## datasetStatistical sound category learning      -0.3342  0.1988  -1.6810
## datasetVowel discrimination (native)             0.3875  0.1302   2.9758
## datasetVowel discrimination (non-native)         0.3575  0.1502   2.3796
## datasetWord segmentation                        -0.1698  0.1211  -1.4022
## year                                            -0.0094  0.0032  -2.9390
##                                                  pval    ci.lb    ci.ub
## intrcpt                                        0.0024   6.8503  31.8558
## response_modeEEG                               0.1007  -0.7447   0.0658
## response_modeeye-tracking                      &lt;.0001  -0.4302  -0.2039
## response_modeNIRS                              0.0150  -0.7303  -0.0784
## response_modeother                             0.8981  -0.5204   0.5932
## mean_age_1                                     0.1224  -0.0002   0.0000
## datasetGaze following                          &lt;.0001   0.7259   1.3584
## datasetInfant directed speech preference       0.0685  -0.0189   0.5169
## datasetLabel advantage in concept learning     0.3437  -0.1311   0.3763
## datasetMutual exclusivity                      &lt;.0001   0.3329   0.8197
## datasetOnline word recognition                 &lt;.0001   0.7916   1.5779
## datasetPhonotactic learning                    0.7678  -0.3504   0.2587
## datasetPointing and vocabulary (concurrent)    0.2273  -0.3027   1.2739
## datasetPointing and vocabulary (longitudinal)  0.7436  -0.5809   0.8135
## datasetSound symbolism                         0.7227  -0.2516   0.3629
## datasetStatistical sound category learning     0.0928  -0.7239   0.0555
## datasetVowel discrimination (native)           0.0029   0.1323   0.6428
## datasetVowel discrimination (non-native)       0.0173   0.0630   0.6520
## datasetWord segmentation                       0.1609  -0.4072   0.0676
## year                                           0.0033  -0.0157  -0.0031
##                                                   
## intrcpt                                         **
## response_modeEEG                                  
## response_modeeye-tracking                      ***
## response_modeNIRS                                *
## response_modeother                                
## mean_age_1                                        
## datasetGaze following                          ***
## datasetInfant directed speech preference         .
## datasetLabel advantage in concept learning        
## datasetMutual exclusivity                      ***
## datasetOnline word recognition                 ***
## datasetPhonotactic learning                       
## datasetPointing and vocabulary (concurrent)       
## datasetPointing and vocabulary (longitudinal)     
## datasetSound symbolism                            
## datasetStatistical sound category learning       .
## datasetVowel discrimination (native)            **
## datasetVowel discrimination (non-native)         *
## datasetWord segmentation                          
## year                                            **
## 
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>RMA with year as moderator is marginal when response mode and method are included as moderator.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">rma</span>(d_calc <span class="op">~</span><span class="st"> </span>response_mode <span class="op">+</span><span class="st"> </span>method <span class="op">+</span><span class="st"> </span>mean_age_<span class="dv">1</span> <span class="op">+</span><span class="st"> </span>dataset <span class="op">+</span><span class="st"> </span>year, 
        <span class="dt">vi =</span> d_var_calc, <span class="dt">data =</span> all_data, <span class="dt">method =</span> <span class="st">&quot;REML&quot;</span>)</code></pre></div>
<pre><code>## 
## Mixed-Effects Model (k = 1022; tau^2 estimator: REML)
## 
## tau^2 (estimated amount of residual heterogeneity):     0.3156 (SE = 0.0178)
## tau (square root of estimated tau^2 value):             0.5618
## I^2 (residual heterogeneity / unaccounted variability): 86.07%
## H^2 (unaccounted variability / sampling variability):   7.18
## R^2 (amount of heterogeneity accounted for):            30.47%
## 
## Test for Residual Heterogeneity: 
## QE(df = 992) = 5093.0893, p-val &lt; .0001
## 
## Test of Moderators (coefficient(s) 2:30): 
## QM(df = 29) = 330.6864, p-val &lt; .0001
## 
## Model Results:
## 
##                                              estimate      se     zval
## intrcpt                                        7.0029  7.1282   0.9824
## response_modeEEG                               0.1811  0.4693   0.3859
## response_modeeye-tracking                     -0.2066  0.0802  -2.5777
## response_modeNIRS                              0.0902  0.3037   0.2970
## response_modeother                             0.1619  0.2902   0.5579
## methodcentral fixation                        -0.1945  0.3166  -0.6143
## methodconditioned head-turn                    0.3330  0.3342   0.9963
## methodforced-choice                            0.5028  0.4102   1.2259
## methodhead-turn preference procedure          -0.2883  0.3239  -0.8900
## methodhigh-amplitude sucking                   0.2949  0.3921   0.7520
## methodhybrid visual habituation procedure     -0.9869  0.4312  -2.2886
## methodlooking while listening                 -0.1376  0.3579  -0.3846
## methododdball                                 -0.6351  0.5977  -1.0625
## methodpointing                                 0.4416  0.5314   0.8310
## methodstimulus alternation                    -0.5074  0.3989  -1.2721
## methodword-object pairing                     -0.6563  0.4746  -1.3830
## mean_age_1                                    -0.0001  0.0000  -1.7688
## datasetGaze following                          0.8577  0.1705   5.0305
## datasetInfant directed speech preference       0.8233  0.2788   2.9528
## datasetLabel advantage in concept learning    -0.0175  0.1338  -0.1311
## datasetMutual exclusivity                      0.4530  0.1262   3.5889
## datasetOnline word recognition                 1.6176  0.3187   5.0755
## datasetPhonotactic learning                    0.5140  0.3045   1.6877
## datasetPointing and vocabulary (concurrent)    0.4146  0.3237   1.2807
## datasetSound symbolism                         0.3894  0.2598   1.4988
## datasetStatistical sound category learning     0.1526  0.3171   0.4813
## datasetVowel discrimination (native)           0.8200  0.2838   2.8890
## datasetVowel discrimination (non-native)       0.7631  0.2970   2.5689
## datasetWord segmentation                       0.4994  0.2827   1.7663
## year                                          -0.0035  0.0036  -0.9741
##                                                pval    ci.lb    ci.ub     
## intrcpt                                      0.3259  -6.9681  20.9740     
## response_modeEEG                             0.6996  -0.7386   1.1008     
## response_modeeye-tracking                    0.0099  -0.3638  -0.0495   **
## response_modeNIRS                            0.7665  -0.5050   0.6854     
## response_modeother                           0.5769  -0.4068   0.7306     
## methodcentral fixation                       0.5390  -0.8151   0.4261     
## methodconditioned head-turn                  0.3191  -0.3221   0.9880     
## methodforced-choice                          0.2202  -0.3011   1.3067     
## methodhead-turn preference procedure         0.3735  -0.9231   0.3466     
## methodhigh-amplitude sucking                 0.4520  -0.4736   1.0633     
## methodhybrid visual habituation procedure    0.0221  -1.8321  -0.1417    *
## methodlooking while listening                0.7006  -0.8392   0.5639     
## methododdball                                0.2880  -1.8065   0.5364     
## methodpointing                               0.4060  -0.6000   1.4833     
## methodstimulus alternation                   0.2033  -1.2892   0.2744     
## methodword-object pairing                    0.1667  -1.5865   0.2738     
## mean_age_1                                   0.0769  -0.0002   0.0000    .
## datasetGaze following                        &lt;.0001   0.5236   1.1919  ***
## datasetInfant directed speech preference     0.0031   0.2768   1.3698   **
## datasetLabel advantage in concept learning   0.8957  -0.2798   0.2448     
## datasetMutual exclusivity                    0.0003   0.2056   0.7003  ***
## datasetOnline word recognition               &lt;.0001   0.9929   2.2422  ***
## datasetPhonotactic learning                  0.0915  -0.0829   1.1108    .
## datasetPointing and vocabulary (concurrent)  0.2003  -0.2199   1.0490     
## datasetSound symbolism                       0.1339  -0.1198   0.8986     
## datasetStatistical sound category learning   0.6303  -0.4689   0.7742     
## datasetVowel discrimination (native)         0.0039   0.2637   1.3763   **
## datasetVowel discrimination (non-native)     0.0102   0.1809   1.3453    *
## datasetWord segmentation                     0.0773  -0.0548   1.0535    .
## year                                         0.3300  -0.0104   0.0035     
## 
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<div id="sample-size-and-year" class="section level2">
<h2>Sample size and year</h2>
<p>One possible explanation for the observed decrease in effect size over time is that sample sizes increase over time. We find evidence to support this.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(all_data , <span class="kw">aes</span>(<span class="dt">x =</span> year, <span class="dt">y =</span> n_total, <span class="dt">color =</span> dataset)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_point</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">facet_wrap</span>(<span class="op">~</span>dataset) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_smooth</span>(<span class="dt">method =</span> <span class="st">&quot;lm&quot;</span>, <span class="dt">colour =</span> <span class="st">&quot;black&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">theme_bw</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">xlab</span>(<span class="st">&quot;published year&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">ylab</span>(<span class="st">&quot;standardized residual effect size&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">theme</span>(<span class="dt">legend.position=</span><span class="st">&quot;none&quot;</span>)</code></pre></div>
<p><img src="reproducibility_inner_files/figure-html/unnamed-chunk-17-1.png" width="672" /></p>
<p>Again, not sure what the right analysis is here. But, predicting sample size with year, controling for everything else, sample sizes tend to get bigger with time.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">kable</span>(<span class="kw">tidy</span>(<span class="kw">lm</span>(n_total <span class="op">~</span><span class="st"> </span>year <span class="op">+</span><span class="st"> </span>response_mode <span class="op">+</span><span class="st"> </span>dataset <span class="op">+</span><span class="st"> </span>method, <span class="dt">data =</span> all_data)))</code></pre></div>
<table>
<thead>
<tr class="header">
<th align="left">term</th>
<th align="right">estimate</th>
<th align="right">std.error</th>
<th align="right">statistic</th>
<th align="right">p.value</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">(Intercept)</td>
<td align="right">-278.9741867</td>
<td align="right">102.4782653</td>
<td align="right">-2.7222766</td>
<td align="right">0.0065969</td>
</tr>
<tr class="even">
<td align="left">year</td>
<td align="right">0.1461106</td>
<td align="right">0.0511476</td>
<td align="right">2.8566444</td>
<td align="right">0.0043708</td>
</tr>
<tr class="odd">
<td align="left">response_modeEEG</td>
<td align="right">-3.2920813</td>
<td align="right">7.1726811</td>
<td align="right">-0.4589750</td>
<td align="right">0.6463526</td>
</tr>
<tr class="even">
<td align="left">response_modeeye-tracking</td>
<td align="right">-0.6806722</td>
<td align="right">1.1980814</td>
<td align="right">-0.5681352</td>
<td align="right">0.5700716</td>
</tr>
<tr class="odd">
<td align="left">response_modeNIRS</td>
<td align="right">-6.6599746</td>
<td align="right">4.6205594</td>
<td align="right">-1.4413784</td>
<td align="right">0.1497931</td>
</tr>
<tr class="even">
<td align="left">response_modeother</td>
<td align="right">-12.5525989</td>
<td align="right">3.9338324</td>
<td align="right">-3.1909338</td>
<td align="right">0.0014626</td>
</tr>
<tr class="odd">
<td align="left">datasetGaze following</td>
<td align="right">17.0304169</td>
<td align="right">2.3378272</td>
<td align="right">7.2847201</td>
<td align="right">0.0000000</td>
</tr>
<tr class="even">
<td align="left">datasetInfant directed speech preference</td>
<td align="right">11.3752408</td>
<td align="right">3.8459743</td>
<td align="right">2.9577007</td>
<td align="right">0.0031729</td>
</tr>
<tr class="odd">
<td align="left">datasetLabel advantage in concept learning</td>
<td align="right">1.4025449</td>
<td align="right">1.6708450</td>
<td align="right">0.8394225</td>
<td align="right">0.4014343</td>
</tr>
<tr class="even">
<td align="left">datasetMutual exclusivity</td>
<td align="right">3.7997471</td>
<td align="right">1.6839775</td>
<td align="right">2.2564120</td>
<td align="right">0.0242616</td>
</tr>
<tr class="odd">
<td align="left">datasetOnline word recognition</td>
<td align="right">25.2856160</td>
<td align="right">4.6741090</td>
<td align="right">5.4097189</td>
<td align="right">0.0000001</td>
</tr>
<tr class="even">
<td align="left">datasetPhonotactic learning</td>
<td align="right">2.8711353</td>
<td align="right">4.3005577</td>
<td align="right">0.6676193</td>
<td align="right">0.5045318</td>
</tr>
<tr class="odd">
<td align="left">datasetPointing and vocabulary (concurrent)</td>
<td align="right">26.4002385</td>
<td align="right">7.6116394</td>
<td align="right">3.4684037</td>
<td align="right">0.0005460</td>
</tr>
<tr class="even">
<td align="left">datasetPointing and vocabulary (longitudinal)</td>
<td align="right">30.2162281</td>
<td align="right">7.4589929</td>
<td align="right">4.0509796</td>
<td align="right">0.0000550</td>
</tr>
<tr class="odd">
<td align="left">datasetSound symbolism</td>
<td align="right">5.1618772</td>
<td align="right">3.7302252</td>
<td align="right">1.3837977</td>
<td align="right">0.1667314</td>
</tr>
<tr class="even">
<td align="left">datasetStatistical sound category learning</td>
<td align="right">2.7514950</td>
<td align="right">4.5136919</td>
<td align="right">0.6095886</td>
<td align="right">0.5422738</td>
</tr>
<tr class="odd">
<td align="left">datasetVowel discrimination (native)</td>
<td align="right">3.3235617</td>
<td align="right">3.9681254</td>
<td align="right">0.8375647</td>
<td align="right">0.4024768</td>
</tr>
<tr class="even">
<td align="left">datasetVowel discrimination (non-native)</td>
<td align="right">5.3348120</td>
<td align="right">4.1677553</td>
<td align="right">1.2800205</td>
<td align="right">0.2008369</td>
</tr>
<tr class="odd">
<td align="left">datasetWord segmentation</td>
<td align="right">5.4715719</td>
<td align="right">3.9508155</td>
<td align="right">1.3849222</td>
<td align="right">0.1663873</td>
</tr>
<tr class="even">
<td align="left">methodcentral fixation</td>
<td align="right">1.6914637</td>
<td align="right">4.8115905</td>
<td align="right">0.3515394</td>
<td align="right">0.7252583</td>
</tr>
<tr class="odd">
<td align="left">methodconditioned head-turn</td>
<td align="right">-2.7241507</td>
<td align="right">5.0429257</td>
<td align="right">-0.5401925</td>
<td align="right">0.5891854</td>
</tr>
<tr class="even">
<td align="left">methodforced-choice</td>
<td align="right">1.4380752</td>
<td align="right">6.0697008</td>
<td align="right">0.2369269</td>
<td align="right">0.8127624</td>
</tr>
<tr class="odd">
<td align="left">methodhead-turn preference procedure</td>
<td align="right">2.4545567</td>
<td align="right">4.9172175</td>
<td align="right">0.4991759</td>
<td align="right">0.6177660</td>
</tr>
<tr class="even">
<td align="left">methodhigh-amplitude sucking</td>
<td align="right">13.1346784</td>
<td align="right">5.7374907</td>
<td align="right">2.2892723</td>
<td align="right">0.0222727</td>
</tr>
<tr class="odd">
<td align="left">methodhybrid visual habituation procedure</td>
<td align="right">3.1963915</td>
<td align="right">6.6534568</td>
<td align="right">0.4804106</td>
<td align="right">0.6310412</td>
</tr>
<tr class="even">
<td align="left">methodlooking while listening</td>
<td align="right">0.2719424</td>
<td align="right">5.4102979</td>
<td align="right">0.0502639</td>
<td align="right">0.9599222</td>
</tr>
<tr class="odd">
<td align="left">methododdball</td>
<td align="right">-5.5962025</td>
<td align="right">9.0519490</td>
<td align="right">-0.6182318</td>
<td align="right">0.5365643</td>
</tr>
<tr class="even">
<td align="left">methodstimulus alternation</td>
<td align="right">1.4314259</td>
<td align="right">6.1126487</td>
<td align="right">0.2341744</td>
<td align="right">0.8148979</td>
</tr>
<tr class="odd">
<td align="left">methodword-object pairing</td>
<td align="right">0.4022508</td>
<td align="right">7.2242633</td>
<td align="right">0.0556805</td>
<td align="right">0.9556075</td>
</tr>
</tbody>
</table>
</div>
</div>
<div id="journal-bias" class="section level1">
<h1>Journal Bias</h1>
<p>Do some journals publish more robust effects than others?</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">pat &lt;-<span class="st"> &quot;developmental science|cognition|child development|cognitive psychology|journal of experimental child psychology|developmental psychology|plos one|language learning and development|infancy|first language|journal of memory and language|proceedings|language and speech|language and cognitive processes|psychological science|unpublished|journal of phonetics|journal of cognition and development|journal of child language|poster|the journal of the acoustical society of america|perception [&amp;] psychophysics|journal of experimental psychology: human perception and performance|psychonomic bulletin [&amp;] review|journal of speech, language, and hearing research|frontiers in psychology|cortex|science|infant behavior and development|bmc neuroscience|the journal of neuroscience|developmental psychobiology|international journal of bilingualism|psicothema|language learning [&amp;] development&quot;</span>

all_data<span class="op">$</span>journal =<span class="st"> </span><span class="kw">str_extract</span>(<span class="kw">tolower</span>(all_data<span class="op">$</span>long_cite), pat)

 all_data <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">filter</span>(<span class="op">!</span><span class="kw">is.na</span>(journal)) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">ggplot</span>( <span class="kw">aes</span>(<span class="dt">x =</span> journal, <span class="dt">y =</span> residual.d.s, <span class="dt">fill =</span> journal)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_violin</span>() <span class="op">+</span>
<span class="st">  </span><span class="co">#geom_dotplot(binaxis=&#39;y&#39;, stackdir=&#39;center&#39;, dotsize = .2, aes(fill = dataset)) +</span>
<span class="st">  </span><span class="kw">ylab</span>(<span class="st">&quot;Standardized residual effect size&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">theme_bw</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">theme</span>(<span class="dt">axis.text.x =</span> <span class="kw">element_text</span>(<span class="dt">angle =</span> <span class="dv">70</span>, <span class="dt">hjust =</span> <span class="dv">1</span>, <span class="dt">size =</span> <span class="dv">9</span>))<span class="op">+</span>
<span class="st">  </span><span class="kw">theme</span>(<span class="dt">legend.position=</span><span class="st">&quot;none&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_hline</span>(<span class="kw">aes</span>(<span class="dt">yintercept =</span> <span class="dv">0</span>)) </code></pre></div>
<p><img src="reproducibility_inner_files/figure-html/unnamed-chunk-19-1.png" width="672" /></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">all_data <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">filter</span>(<span class="op">!</span><span class="kw">is.na</span>(journal)) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">group_by</span>(journal) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">multi_boot_standard</span>(<span class="dt">col =</span> <span class="st">&quot;residual.d.s&quot;</span>)  <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">ggplot</span>( <span class="kw">aes</span>(<span class="dt">x =</span> <span class="kw">reorder</span>(journal, mean), <span class="dt">y =</span> mean, <span class="dt">fill =</span> journal)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_bar</span>(<span class="dt">position=</span><span class="st">&quot;dodge&quot;</span>, <span class="dt">stat=</span><span class="st">&quot;identity&quot;</span>) <span class="op">+</span><span class="st">  </span>
<span class="st">  </span><span class="kw">geom_errorbar</span>(<span class="kw">aes</span>(<span class="dt">ymin =</span> ci_lower, <span class="dt">ymax=</span> ci_upper), 
                <span class="dt">width=</span><span class="fl">0.2</span>, <span class="dt">position=</span><span class="st">&quot;dodge&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">ylab</span>(<span class="st">&quot;Standardized residual effect size&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">xlab</span>(<span class="st">&quot;journal&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">theme_bw</span>() <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">theme</span>(<span class="dt">legend.position=</span><span class="st">&quot;none&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">theme</span>(<span class="dt">axis.text.x =</span> <span class="kw">element_text</span>(<span class="dt">angle =</span> <span class="dv">70</span>, <span class="dt">hjust =</span> <span class="dv">1</span>, <span class="dt">size =</span> <span class="dv">9</span>)) </code></pre></div>
<p><img src="reproducibility_inner_files/figure-html/unnamed-chunk-19-2.png" width="672" /></p>
<p>No evidence of major bias by journal.</p>
<div id="impact-factor" class="section level2">
<h2>Impact factor</h2>
<p>Is the impact factor of a journal related to its effect size?</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">d.if =<span class="st"> </span><span class="kw">read.csv</span>(<span class="st">&quot;impact_factors.csv&quot;</span>)

all_data =<span class="st"> </span><span class="kw">left_join</span>(all_data, d.if, <span class="dt">by =</span> <span class="st">&quot;journal&quot;</span>)

<span class="kw">ggplot</span>(all_data, <span class="kw">aes</span>(IF)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_histogram</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">theme_bw</span>()</code></pre></div>
<p><img src="reproducibility_inner_files/figure-html/unnamed-chunk-20-1.png" width="672" /></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">all_data <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">filter</span>(<span class="op">!</span><span class="kw">is.na</span>(IF)) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">filter</span>(IF <span class="op">&lt;</span><span class="st"> </span><span class="dv">10</span>) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x=</span> IF, <span class="dt">y =</span> residual.d.s)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_point</span>(<span class="kw">aes</span>(<span class="dt">color =</span> dataset)) <span class="op">+</span>
<span class="st">  </span><span class="kw">xlab</span>(<span class="st">&quot;Impact factor&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">ylab</span>(<span class="st">&quot;standardized residual effect size&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_smooth</span>(<span class="dt">method =</span> <span class="st">&quot;lm&quot;</span>, <span class="dt">color =</span> <span class="st">&quot;black&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">theme_bw</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">theme</span>(<span class="dt">legend.position=</span><span class="st">&quot;none&quot;</span>) </code></pre></div>
<p><img src="reproducibility_inner_files/figure-html/unnamed-chunk-20-2.png" width="672" /></p>
<p>No evidence for an effect of impact factor on effect size.</p>
<p>Correlation between residualized effect sizes and impact factors:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">all_data <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">filter</span>(<span class="op">!</span><span class="kw">is.na</span>(IF)) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">filter</span>(IF <span class="op">&lt;</span><span class="st"> </span><span class="dv">10</span>)  <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">do</span>(<span class="kw">tidy</span>(<span class="kw">cor.test</span>(.<span class="op">$</span>residual.d.s,.<span class="op">$</span>IF))) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">kable</span>()</code></pre></div>
<table>
<thead>
<tr class="header">
<th align="right">estimate</th>
<th align="right">statistic</th>
<th align="right">p.value</th>
<th align="right">parameter</th>
<th align="right">conf.low</th>
<th align="right">conf.high</th>
<th align="left">method</th>
<th align="left">alternative</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">0.0424565</td>
<td align="right">1.24111</td>
<td align="right">0.2149063</td>
<td align="right">853</td>
<td align="right">-0.0246602</td>
<td align="right">0.1091922</td>
<td align="left">Pearson’s product-moment correlation</td>
<td align="left">two.sided</td>
</tr>
</tbody>
</table>
<p>No evidence of impact factor on residiualized effect size.</p>
<p>Meta-analytic model:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">rma</span>(d_calc <span class="op">~</span><span class="st"> </span>response_mode <span class="op">+</span><span class="st"> </span>method <span class="op">+</span><span class="st"> </span>mean_age_<span class="dv">1</span> <span class="op">+</span><span class="st"> </span>dataset <span class="op">+</span><span class="st"> </span>IF, 
        <span class="dt">vi =</span> d_var_calc, <span class="dt">data =</span> all_data, <span class="dt">method =</span> <span class="st">&quot;REML&quot;</span>)</code></pre></div>
<pre><code>## 
## Mixed-Effects Model (k = 859; tau^2 estimator: REML)
## 
## tau^2 (estimated amount of residual heterogeneity):     0.3544 (SE = 0.0215)
## tau (square root of estimated tau^2 value):             0.5953
## I^2 (residual heterogeneity / unaccounted variability): 87.19%
## H^2 (unaccounted variability / sampling variability):   7.80
## R^2 (amount of heterogeneity accounted for):            26.91%
## 
## Test for Residual Heterogeneity: 
## QE(df = 830) = 4436.0357, p-val &lt; .0001
## 
## Test of Moderators (coefficient(s) 2:29): 
## QM(df = 28) = 242.6648, p-val &lt; .0001
## 
## Model Results:
## 
##                                              estimate      se     zval
## intrcpt                                       -0.0009  0.4661  -0.0019
## response_modeEEG                               0.1420  0.4964   0.2861
## response_modeeye-tracking                     -0.2188  0.0871  -2.5132
## response_modeNIRS                             -0.5472  0.3957  -1.3829
## response_modeother                             0.2234  0.3996   0.5589
## methodcentral fixation                        -0.1517  0.3339  -0.4542
## methodconditioned head-turn                    0.3401  0.3523   0.9654
## methodforced-choice                            0.6226  0.4506   1.3816
## methodhead-turn preference procedure          -0.2438  0.3415  -0.7141
## methodhigh-amplitude sucking                   0.4167  0.4110   1.0139
## methodhybrid visual habituation procedure     -1.1839  0.4890  -2.4210
## methodlooking while listening                 -0.0872  0.3802  -0.2293
## methododdball                                 -0.8288  0.6443  -1.2864
## methodpointing                                 0.3722  0.6348   0.5863
## methodword-object pairing                     -0.6055  0.4960  -1.2208
## mean_age_1                                    -0.0001  0.0001  -1.9582
## datasetGaze following                          0.7950  0.1862   4.2704
## datasetInfant directed speech preference       0.7394  0.3234   2.2862
## datasetLabel advantage in concept learning    -0.0800  0.1389  -0.5760
## datasetMutual exclusivity                      0.3759  0.1229   3.0584
## datasetOnline word recognition                 1.6138  0.3748   4.3064
## datasetPhonotactic learning                    0.3914  0.3637   1.0763
## datasetPointing and vocabulary (concurrent)    0.4662  0.3624   1.2867
## datasetSound symbolism                         0.3642  0.3122   1.1663
## datasetStatistical sound category learning     0.4166  0.3872   1.0758
## datasetVowel discrimination (native)           0.8357  0.3299   2.5330
## datasetVowel discrimination (non-native)       0.7640  0.3432   2.2260
## datasetWord segmentation                       0.4844  0.3273   1.4801
## IF                                             0.0102  0.0103   0.9869
##                                                pval    ci.lb    ci.ub     
## intrcpt                                      0.9985  -0.9145   0.9127     
## response_modeEEG                             0.7748  -0.8308   1.1149     
## response_modeeye-tracking                    0.0120  -0.3894  -0.0482    *
## response_modeNIRS                            0.1667  -1.3229   0.2284     
## response_modeother                           0.5762  -0.5599   1.0066     
## methodcentral fixation                       0.6497  -0.8061   0.5028     
## methodconditioned head-turn                  0.3343  -0.3504   1.0307     
## methodforced-choice                          0.1671  -0.2606   1.5058     
## methodhead-turn preference procedure         0.4752  -0.9131   0.4254     
## methodhigh-amplitude sucking                 0.3106  -0.3888   1.2221     
## methodhybrid visual habituation procedure    0.0155  -2.1424  -0.2255    *
## methodlooking while listening                0.8186  -0.8324   0.6580     
## methododdball                                0.1983  -2.0915   0.4340     
## methodpointing                               0.5577  -0.8720   1.6164     
## methodword-object pairing                    0.2222  -1.5776   0.3666     
## mean_age_1                                   0.0502  -0.0003   0.0000    .
## datasetGaze following                        &lt;.0001   0.4301   1.1599  ***
## datasetInfant directed speech preference     0.0222   0.1055   1.3733    *
## datasetLabel advantage in concept learning   0.5646  -0.3523   0.1923     
## datasetMutual exclusivity                    0.0022   0.1350   0.6168   **
## datasetOnline word recognition               &lt;.0001   0.8793   2.3483  ***
## datasetPhonotactic learning                  0.2818  -0.3213   1.1042     
## datasetPointing and vocabulary (concurrent)  0.1982  -0.2440   1.1765     
## datasetSound symbolism                       0.2435  -0.2478   0.9761     
## datasetStatistical sound category learning   0.2820  -0.3424   1.1756     
## datasetVowel discrimination (native)         0.0113   0.1891   1.4824    *
## datasetVowel discrimination (non-native)     0.0260   0.0913   1.4368    *
## datasetWord segmentation                     0.1389  -0.1571   1.1260     
## IF                                           0.3237  -0.0101   0.0305     
## 
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<div id="are-impact-factors-related-to-sample-sizes" class="section level3">
<h3>Are impact factors related to sample sizes?</h3>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">all_data <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">filter</span>(<span class="op">!</span><span class="kw">is.na</span>(IF)) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">filter</span>(IF <span class="op">&lt;</span><span class="st"> </span><span class="dv">10</span>) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x=</span> IF, <span class="dt">y =</span> n_total)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_point</span>(<span class="kw">aes</span>(<span class="dt">color =</span> dataset)) <span class="op">+</span>
<span class="st">  </span><span class="kw">xlab</span>(<span class="st">&quot;Impact factor&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">ylab</span>(<span class="st">&quot;Sample size&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_smooth</span>(<span class="dt">method =</span> <span class="st">&quot;lm&quot;</span>, <span class="dt">color =</span> <span class="st">&quot;black&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">theme_bw</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">theme</span>(<span class="dt">legend.position=</span><span class="st">&quot;none&quot;</span>) </code></pre></div>
<p><img src="reproducibility_inner_files/figure-html/unnamed-chunk-23-1.png" width="672" /></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">all_data <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">filter</span>(<span class="op">!</span><span class="kw">is.na</span>(IF)) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">filter</span>(IF <span class="op">&lt;</span><span class="st"> </span><span class="dv">10</span>)  <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">do</span>(<span class="kw">tidy</span>(<span class="kw">cor.test</span>(.<span class="op">$</span>n_total,.<span class="op">$</span>IF))) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">kable</span>()</code></pre></div>
<table>
<thead>
<tr class="header">
<th align="right">estimate</th>
<th align="right">statistic</th>
<th align="right">p.value</th>
<th align="right">parameter</th>
<th align="right">conf.low</th>
<th align="right">conf.high</th>
<th align="left">method</th>
<th align="left">alternative</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">-0.0925634</td>
<td align="right">-2.715077</td>
<td align="right">0.0067599</td>
<td align="right">853</td>
<td align="right">-0.1586254</td>
<td align="right">-0.0256762</td>
<td align="left">Pearson’s product-moment correlation</td>
<td align="left">two.sided</td>
</tr>
</tbody>
</table>
<p>No evidence of impact factor on sample size.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Citation network</span>
<span class="co"># using google scholar</span></code></pre></div>
</div>
</div>
</div>



</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
